{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa72189",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1423df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "## %pip install matplotlib\n",
    "## %pip install wordcloud\n",
    "## %pip install nltk\n",
    "import numpy as np                              # For numerical operations\n",
    "import matplotlib.pyplot as plt                 # For data visualization\n",
    "%matplotlib inline\n",
    "import pandas as pd                             # For data manipulation and analysis\n",
    "\n",
    "from wordcloud import WordCloud                 # For generating word clouds\n",
    "\n",
    "import nltk                                     # For natural language processing\n",
    "from nltk.corpus import stopwords               # For accessing stopwords\n",
    "\n",
    "\n",
    "# Downloading NLTK resources\n",
    "nltk.download('punkt')                          # Downloading the punkt tokenizer\n",
    "nltk.download('punkt_tab')                      # Downloading the punkt tokenizer for tab-separated text\n",
    "nltk.download('stopwords')                      # Downloading stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1603ff",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b935dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/rkydx/datasets_repo/refs/heads/main/spam.csv')      # Reading the dataset from a URL raw GitHub link\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5202061",
   "metadata": {},
   "source": [
    "### Data Preprocessing - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797a1394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78724df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns for better clarity\n",
    "df.rename(columns={'v1': 'target', 'v2': 'text'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48b9cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(403)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd44f1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b0df6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicate values\n",
    "df = df.drop_duplicates(keep='first')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93aa28a",
   "metadata": {},
   "source": [
    "### Data Preprocessing - Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40839a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install scikit-learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Encode the 'target' column\n",
    "# Learns all unique values in the column (fit) and converts them into numbers (transform)\n",
    "df['target'] = le.fit_transform(df['target'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea5ab2",
   "metadata": {},
   "source": [
    "### Data Preprocessing - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eace97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Porter Stemmer for text stemming, which reduces words to their root form\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Importing the string module for handling special characters and punctuation\n",
    "import string\n",
    "\n",
    "# Creating an instance of the Porter Stemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32225183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d92f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase transformation and text preprocessing function\n",
    "def transform_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and common special characters\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenization - splitting text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Stemming and removing stopwords\n",
    "    y = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            y.append(ps.stem(word))\n",
    "    \n",
    "    return \" \".join(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d7171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'per request mell mell oru minnaminungint nurungu vettam set callertun caller press 9 copi friend callertun'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_text(\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37434c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5a22e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the text transformation function to the 'text' column and creating a new column 'transformed_text'\n",
    "df['transformed_text'] = df['text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "305e1ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4          nah dont think goe usf live around though  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd3a5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction using TF-IDF Vectorizer\n",
    "# It converts text data into numerical format by calculating the importance of words in documents, considering their frequency and distribution.\n",
    "# Higher weight to important words, lower weight to common words. \n",
    "# The resulting vectors can be used as input for machine learning models. \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Keep only the top 500 most important words from the whole dataset\n",
    "tfid = TfidfVectorizer(max_features = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bed11d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the 'transformed_text' column to create feature matrix X and target vector y\n",
    "X = tfid.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['target'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd1182",
   "metadata": {},
   "source": [
    "### Data Preprocessing - Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba013879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10fc7b",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "> Different models and is best for:\n",
    "```\n",
    "| Model                             | Category         | Best for                                       |\n",
    "| --------------------------------- | ---------------- | ---------------------------------------------- |\n",
    "| `LogisticRegression`              | Linear model     | Fast, works well for text classification       |\n",
    "| `SVC` (Support Vector Classifier) | SVM              | Powerful for small/medium text data            |\n",
    "| `MultinomialNB`                   | Na√Øve Bayes      | **Very good for text (spam classification)**   |\n",
    "| `DecisionTreeClassifier`          | Tree model       | Simple but can overfit                         |\n",
    "| `KNeighborsClassifier`            | Distance-based   | Not great for high-dim text data               |\n",
    "| `RandomForestClassifier`          | Ensemble (trees) | Strong, stable, avoids overfitting             |\n",
    "| `AdaBoostClassifier`              | Boosting         | Focuses on correcting errors                   |\n",
    "| `BaggingClassifier`               | Ensemble         | Reduces variance, stable model                 |\n",
    "| `ExtraTreesClassifier`            | Random Trees     | Faster than RandomForest                       |\n",
    "| `GradientBoostingClassifier`      | Boosting         | Strong performance but slow                    |\n",
    "| `XGBClassifier`                   | Extreme Boosting | **One of the best ML models for tabular data** |\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of various machine learning models/algorithms\n",
    "# %pip install xgboost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a66c4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    #\"SVC\": SVC(kernel=\"sigmoid\", gamma=\"1.0\"),          \n",
    "    \"SVC\": SVC(kernel=\"rbf\", gamma=\"scale\"),           # rbf is usually a better default\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=5, random_state=2),\n",
    "    \"LogisticRegression\": LogisticRegression(solver=\"liblinear\", penalty=\"l1\", random_state=2),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=50, random_state=2, n_jobs=-1),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=50, random_state=2),\n",
    "    \"Bagging\": BaggingClassifier(n_estimators=50, random_state=2, n_jobs=-1),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(n_estimators=50, random_state=2, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=50, random_state=2),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=50, random_state=2, use_label_encoder=False, eval_metric='logloss', n_jobs=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e8d2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a classifier\n",
    "def train_and_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Train one classifier and return metrics dict.\"\"\"\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        # \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        # \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        # \"confusion_matrix\": confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d98806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVC ...\n",
      "SVC - acc: 0.9729, prec: 0.9825\n",
      "\n",
      "Training KNN ...\n",
      "KNN - acc: 0.9284, prec: 1.0000\n",
      "\n",
      "Training MultinomialNB ...\n",
      "MultinomialNB - acc: 0.9710, prec: 0.9655\n",
      "\n",
      "Training DecisionTree ...\n",
      "DecisionTree - acc: 0.9352, prec: 0.8989\n",
      "\n",
      "Training LogisticRegression ...\n",
      "LogisticRegression - acc: 0.9662, prec: 0.9478\n",
      "\n",
      "Training RandomForest ...\n",
      "RandomForest - acc: 0.9720, prec: 0.9504\n",
      "\n",
      "Training AdaBoost ...\n",
      "AdaBoost - acc: 0.9246, prec: 0.8750\n",
      "\n",
      "Training Bagging ...\n",
      "Bagging - acc: 0.9632, prec: 0.9032\n",
      "\n",
      "Training ExtraTrees ...\n",
      "ExtraTrees - acc: 0.9758, prec: 0.9449\n",
      "\n",
      "Training GradientBoosting ...\n",
      "GradientBoosting - acc: 0.9497, prec: 0.9388\n",
      "\n",
      "Training XGBoost ...\n",
      "XGBoost - acc: 0.9710, prec: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIML\\MLOps\\MLOps_VikashDas\\myenv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:29:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for name, clf in models.items():\n",
    "    try:\n",
    "        print(f\"\\nTraining {name} ...\")\n",
    "        metrics = train_and_evaluate(clf, X_train, y_train, X_test, y_test)\n",
    "        results[name] = metrics\n",
    "        print(f\"{name} - acc: {metrics['accuracy']:.4f}, prec: {metrics['precision']:.4f}\")\n",
    "        # print(f\"{name} - acc: {metrics['accuracy']:.4f}, prec: {metrics['precision']:.4f}, recall: {metrics['recall']:.4f}, f1: {metrics['f1']:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name} failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
